Below we source the file of functions used to clean the data as well as any required packages.

```{r}
source("00_requirements.R")
source("01_funct_dataCleaning.R")
```

Load data

```{r}
FemaleLabor <- data.frame(read.csv("00_LaborForceData.csv"))
EducationExp <- data.frame(read.csv("00_GovEducationExpense.csv"))
BirthRate <- data.frame(read.csv("00_BirthRate.csv"))
FertilityRate <- data.frame(read.csv("00_FertilityRate.csv"))
ParentalLeave <- data.frame(read.csv("00_ParentalLeave.csv"))
TertiaryEnroll <- data.frame(read.csv("00_TertiaryEnrollmentRate.csv"))

#Control variables
GDP <- data.frame(read.csv("00_GDPcurrentUS.csv"))
Population <- data.frame(read.csv("00_Population.csv"))
```

We'll remove any unnecessary variables from the datasets then apply the functions defined above to each dataset.

```{r}
keep_col <- c("REF_AREA", "REF_AREA_LABEL", "TIME_PERIOD", "OBS_VALUE")

edu_clean <- EducationExp[,keep_col]
flabor_clean <- FemaleLabor[,keep_col]
brate_clean <- BirthRate[,keep_col]
fert_clean <- FertilityRate[,keep_col]
leave_clean <- ParentalLeave[,-c(1,2)]
enroll_clean <- TertiaryEnroll[,-c(1,2)]

#controls
gdp_clean <- GDP[, keep_col]
population_clean <- Population[, keep_col]
```

```{r}
df_list <- list(edu_clean, flabor_clean, brate_clean, fert_clean, leave_clean, enroll_clean, gdp_clean, population_clean)

#check for missing values
for (d in df_list) {
  print(sum(is.na(d)))
}
```
Parental leave and Tertiary Enrollment are structured a bit differently from the other datasets. We need to separate male and female values and consider what we want to include in our model.

```{r}
#separating male and female values into their own columns
leave_sep <- leave_clean %>%
  pivot_wider(names_from = Disaggregation, values_from = Value, names_prefix = "days_")

enroll_sep <- enroll_clean %>%
  pivot_wider(names_from = Disaggregation, values_from = Value, names_prefix = "enrolled_")

```

We want to combine all of our data into one dataframe. However, some of the column names are not very descriptive so we must change the column names first.

```{r}
colnames(edu_clean)[colnames(edu_clean) == "OBS_VALUE"] <- "edu_exp"
colnames(flabor_clean)[colnames(flabor_clean) == "OBS_VALUE"] <- "female_labor_rate"
colnames(brate_clean)[colnames(brate_clean) == "OBS_VALUE"] <- "birth_rate"
colnames(fert_clean)[colnames(fert_clean) == "OBS_VALUE"] <- "fertility_rate"
colnames(gdp_clean)[colnames(gdp_clean) == "OBS_VALUE"] <- "gdp"
colnames(population_clean)[colnames(population_clean) == "OBS_VALUE"] <- "population"
```

Now we can merge all of our datasets into one dataframe

```{r}
df <- edu_clean %>%
  left_join(flabor_clean, by = c("REF_AREA", "REF_AREA_LABEL", "TIME_PERIOD")) %>%
  left_join(brate_clean, by = c("REF_AREA", "REF_AREA_LABEL", "TIME_PERIOD")) %>%
  left_join(fert_clean, by = c("REF_AREA", "REF_AREA_LABEL", "TIME_PERIOD")) %>%
  left_join(leave_sep, by = c("REF_AREA" = "Country.Code", "REF_AREA_LABEL" = "Country.Name", "TIME_PERIOD" = "Year")) %>%
  left_join(enroll_sep, by = c("REF_AREA" = "Country.Code", "REF_AREA_LABEL" = "Country.Name", "TIME_PERIOD" = "Year")) %>%
  left_join(gdp_clean, by = c("REF_AREA", "REF_AREA_LABEL", "TIME_PERIOD")) %>%
  left_join(population_clean, by = c("REF_AREA", "REF_AREA_LABEL", "TIME_PERIOD"))

colnames(df)[colnames(df) == "REF_AREA"] <- "country_code"
colnames(df)[colnames(df) == "REF_AREA_LABEL"] <- "country"
colnames(df)[colnames(df) == "TIME_PERIOD"] <- "year"
```


```{r}
sum(is.na(df))
colSums(is.na(df)) / nrow(df)

colSums(!is.na(df))
```
Certain columns have a large proportion of missing values which can be worrying when training models. However, these columns still have a large amount of observations despite the proportion of missing values. Since we plan on running a regression on our data, the high proportion of missing data should not have too large of an effect on our model so long as we have a large enough sample size. We can also omit different variables based on missingness and test the accuracy of different regression models. 

#Year
```{r}
hist(df$year)
```
There more data from 2000 to 2020 and less data before 2000 and after 2020.

#Missingness by year

```{r}
missing_year_table <- df %>%
  group_by(year) %>%
  summarize(across(everything(), ~sum(is.na(.)))) %>%
  mutate(total_missing = rowSums(across(-year)))

ggplot(missing_year_table, aes(x = factor(year), y = total_missing)) +
  geom_col() +
  labs(
    title = "Total missing values per year",
    x = "Year",
    y = "Total missing values"
  ) +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))
```
#Missingness by country

```{r}
missing_country <- df %>%
  group_by(country) %>%
  summarize(across(everything(), ~sum(is.na(.)))) %>%
  mutate(total_missing = rowSums(across(-country)))

missing_prop_country <- df %>%
  group_by(country) %>%
  summarize(across(everything(), ~mean(is.na(.))), .groups = "drop") %>%
  mutate(total_missing_prop = rowMeans(across(-country)))

#remove countries with too many missing values
country_keep <- missing_prop_country %>%
  filter(total_missing_prop <= 0.25) %>%
  pull(country)

df <- df %>%
  filter(country %in% country_keep)
```


Our preliminary regression would most likely look something like:

$$
FemaleLabor_i = \beta_0 + \beta_1 EducationExpenditure + \beta_2 BirthRate + \beta_3 FertilityRate + \\ \beta_4 ParentalLeave + \beta_5 TertiaryEnrollment + \beta_6GDP + \beta_7Population + \varepsilon_i
$$
We can explore other options within our model as we explore the relationships between different variables. Introducing exponential variables, interaction terms, time-fixed effects, applying log transformations, or even removing some variables may help improve the accuracy of our model.

We can start making preliminary visualizations for each variable.

#Government Expenditure on Education (% of GDP)
```{r}
summary(df$edu_exp)
hist(df$edu_exp, breaks = 75,
     main = "Distribution of Government Expenditure on Education",
     xlab = "Government Expenditure on Education (% of GDP)")
```
Government expenditure on education displays a right skewed distribution. There are not many outliers, but the outliers that do exist are rather extreme. It may be wise to perform a log transformation to reduce skewness and combat extreme values.


#Birth Rate (per 1000 people)
```{r}
summary(df$birth_rate)
hist(df$birth_rate, breaks = 50,
     main = "Distribution of Birth Rate",
     xlab = "Birth Rate (per 1000 people)")
```
Birth Rates show a right skewed distribution. However, the data is relatively spread out with few to no outliers. Log transformation seems to be unnecessary for birth rates. Something to keep in mind when running birth rates as an independent variable in our regression is reverse causality. We would be exploring the effect of birth rate on female labor rate when in reality it may be female labor rate causing birth rate to behave a certain way. 

#Fertility Rate (births per woman)
```{r}
summary(df$fertility_rate)
hist(df$fertility_rate, breaks = 50,
     main = "Distribution of Fertility Rate",
     xlab = "Fertility Rate (births per woman)")
```
Fertility Rate shows a right skewed distribution. Similar to birth rate there is a relatively even spread of data with few to no outliers. Log transformation seems to be unnecessary. However, we must be careful when including both fertility rate and birth rate in our model it may risk multicollinearity. 

#Length of paid parental leave (calendar days)
```{r}
#mother
summary(df$days_female)
#father
summary(df$days_male)
hist(df$days_female, breaks = 50,
     main = "Distribution of Paid Maternal Leave",
     xlab = "Length of Paid Maternal Leave (calendar days)")
hist(df$days_male, breaks = 50,
     main = "Distribution of Paid Paternal Leave",
     xlab = "Length of Paid Paternal Leave (calendar days)")
```
Data for paid parental leave is extremely right skewed and has many extreme outliers for both genders. Log transformation will most likely be necessary if we want to include this in our model. Paid parental leave is one of the variables with a significant amount of missing values. It should not have too large of an effect on the regression as there are still a significant amount of observations, but it is still something we should be careful about.

#School enrollment, tertiary (% gross)
```{r}
#Female
summary(df$enrolled_female)
#Male
summary(df$enrolled_male)
#Total
summary(df$enrolled_total)
hist(df$enrolled_male, breaks = 50,
     main = "Distribution of Male Tertiary School Enrollment Rate",
     xlab = "Male Tertiary School Enrollment (% gross)")
hist(df$enrolled_female, breaks = 50,
     main = "Distribution of Female Tertiary School Enrollment Rate",
     xlab = "Female Tertiary School Enrollment (% gross)")
hist(df$enrolled_total, breaks = 50,
     main = "Distribution of Tertiary School Enrollment Rate",
     xlab = "Tertiary School Enrollment (% gross)")
```
Tertiary enrollemtn also shows a right skewed distribution. There is a relatively even spread of the data with few outliers. 
#GDP (current US$)
```{r}
summary(df$gdp)
hist(df$gdp, breaks = 50,
     main = "Distribution of GDP",
     xlab = "GDP (current US$)")
```
GDP is heavily right skewed with some extreme outliers. Log transformation will probably be necessary for this variable.
#Population
```{r}
summary(df$population)
hist(df$population, breaks = 50,
     main = "Distribution of Population",
     xlab = "Population")
```
#Female Labor Participation Rate (% of female population age 15+)
```{r}
summary(df$female_labor_rate)
hist(df$female_labor_rate, breaks = 50,
     main = "Distribution of Female Labor Participation Rate",
     xlab = "Female Labor Participation Rate (% of female population age 15+)")
```
Female labor participation rate follow a distribution with little skewness and few outliers.

#Multiple variable visualizations

#Education Expenditure vs Female Labor

```{r}
plot(
  x = df$edu_exp, y = df$female_labor_rate,
  main = "Education Expenditure vs Female Labor Rate",
  xlab = "Education Expenditure", ylab = "Female Labor Rate",
  col = factor(df$country)
)
```
No particularly clear patterns. Data seems to be rather skewed with a few extreme outliers. Could be a good idea to log education expenditure.

#Birth Rates vs Female Labor

```{r}
plot(
  x = df$birth_rate, y = df$female_labor_rate,
  main = "Birth Rate vs Female Labor Rate",
  xlab = "Birth Rate", ylab = "Female Labor Rate",
  col = factor(df$country)
)
```
No clear patterns between the two variables. Some countries show some patterns but overall there seems to be little to no relationship between the two variables.

#Fertility Rates vs Female Labor

```{r}
plot(
  x = df$fertility_rate, y = df$female_labor_rate,
  main = "Fertility Rates vs Female Labor Rate",
  xlab = "Fertility Rate", ylab = "Female Labor Rate",
  col = factor(df$country)
)
```
Same as Birth rate.

#Parental Leave vs Female Labor

```{r}
#Maternal
plot(
  x = df$days_female, y = df$female_labor_rate,
  main = "Days of Maternal Leave Given vs Female Labor Rate",
  xlab = "Days of Maternal Leave", ylab = "Female Labor Rate",
  col = factor(df$country)
)

#Paternal
plot(
  x = df$days_male, y = df$female_labor_rate,
  main = "Days of Paternal Leave Given vs Female Labor Rate",
  xlab = "Days of Paternal Leave", ylab = "Female Labor Rate",
  col = factor(df$country)
)

```
Once again no clear pattern

#Correlation Matrix

```{r}
full_cmat <- cor_mat(
  df,
  vars = c(3:ncol(df)),
  method = "pearson",
  alternative = "two.sided",
  conf.level = 0.95
)
print(full_cmat)
```
This is a correlation matrix for all variables. There are a lot of values and we don't have p-values so it is difficult to come to any conclusions from just this. Let's make a smaller correlation matrix as we aim to create our first regression model with fewer, more basic variables.


```{r}
basic_cmat <- cor_mat(
  df,
  vars = c("year", "edu_exp", "female_labor_rate", "gdp", "population", "birth_rate", "fertility_rate"),
  method = "pearson",
  alternative = "two.sided",
  conf.level = 0.95
)
print(basic_cmat)


cor_get_pval(basic_cmat)
```
Now we have the reduced correlation matrix with p values, but we can also create a visualization to have a better understanding of the results.

```{r}
basic_cmat %>%
  cor_reorder() %>%
  pull_lower_triangle() %>%
  cor_plot(label = TRUE)
```
#Female_labor_rate & edu_exp only
```{r}
labor_exp_model <- lm(female_labor_rate ~ edu_exp, data = df)
summary(labor_exp_model)
```

#First Basic Model
```{r}
basic_model <- lm(female_labor_rate ~ edu_exp + year + gdp + population, data = df)
summary(basic_model)
```















