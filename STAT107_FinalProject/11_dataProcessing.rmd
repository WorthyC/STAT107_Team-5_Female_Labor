Below we source the file of functions used to clean the data as well as any required packages.

```{r}
source("00_requirements.R")
source("01_funct_dataCleaning.R")
```

Load data

```{r}
FemaleLabor <- data.frame(read.csv("00_LaborForceData.csv"))
EducationExp <- data.frame(read.csv("00_GovEducationExpense.csv"))
BirthRate <- data.frame(read.csv("00_BirthRate.csv"))
FertilityRate <- data.frame(read.csv("00_FertilityRate.csv"))
ParentalLeave <- data.frame(read.csv("00_ParentalLeave.csv"))
TertiaryEnroll <- data.frame(read.csv("00_TertiaryEnrollmentRate.csv"))

#Control variables
GDP <- data.frame(read.csv("00_GDPcurrentUS.csv"))
Population <- data.frame(read.csv("00_Population.csv"))
```

We'll remove any unnecessary variables from the datasets then apply the functions defined above to each dataset.

```{r}
keep_col <- c("REF_AREA", "REF_AREA_LABEL", "TIME_PERIOD", "OBS_VALUE")

edu_clean <- EducationExp[,keep_col]
flabor_clean <- FemaleLabor[,keep_col]
brate_clean <- BirthRate[,keep_col]
fert_clean <- FertilityRate[,keep_col]
leave_clean <- ParentalLeave[,-c(1,2)]
enroll_clean <- TertiaryEnroll[,-c(1,2)]

#controls
gdp_clean <- GDP[, keep_col]
population_clean <- Population[, keep_col]
```

```{r}
df_list <- list(edu_clean, flabor_clean, brate_clean, fert_clean, leave_clean, enroll_clean, gdp_clean, population_clean)

#check for missing values
for (d in df_list) {
  print(sum(is.na(d)))
}
```
Parental leave and Tertiary Enrollment are structured a bit differently from the other datasets. We need to separate male and female values and consider what we want to include in our model.

```{r}
#separating male and female values into their own columns
leave_sep <- leave_clean %>%
  pivot_wider(names_from = Disaggregation, values_from = Value, names_prefix = "days_")

enroll_sep <- enroll_clean %>%
  pivot_wider(names_from = Disaggregation, values_from = Value, names_prefix = "enrolled_")

```

We want to combine all of our data into one dataframe. However, some of the column names are not very descriptive so we must change the column names first.

```{r}
colnames(edu_clean)[colnames(edu_clean) == "OBS_VALUE"] <- "edu_exp"
colnames(flabor_clean)[colnames(flabor_clean) == "OBS_VALUE"] <- "female_labor_rate"
colnames(brate_clean)[colnames(brate_clean) == "OBS_VALUE"] <- "birth_rate"
colnames(fert_clean)[colnames(fert_clean) == "OBS_VALUE"] <- "fertility_rate"
colnames(gdp_clean)[colnames(gdp_clean) == "OBS_VALUE"] <- "gdp"
colnames(population_clean)[colnames(population_clean) == "OBS_VALUE"] <- "population"
```

Now we can merge all of our datasets into one dataframe

```{r}
df <- edu_clean %>%
  left_join(flabor_clean, by = c("REF_AREA", "REF_AREA_LABEL", "TIME_PERIOD")) %>%
  left_join(brate_clean, by = c("REF_AREA", "REF_AREA_LABEL", "TIME_PERIOD")) %>%
  left_join(fert_clean, by = c("REF_AREA", "REF_AREA_LABEL", "TIME_PERIOD")) %>%
  left_join(leave_sep, by = c("REF_AREA" = "Country.Code", "REF_AREA_LABEL" = "Country.Name", "TIME_PERIOD" = "Year")) %>%
  left_join(enroll_sep, by = c("REF_AREA" = "Country.Code", "REF_AREA_LABEL" = "Country.Name", "TIME_PERIOD" = "Year")) %>%
  left_join(gdp_clean, by = c("REF_AREA", "REF_AREA_LABEL", "TIME_PERIOD")) %>%
  left_join(population_clean, by = c("REF_AREA", "REF_AREA_LABEL", "TIME_PERIOD"))

colnames(df)[colnames(df) == "REF_AREA"] <- "country_code"
colnames(df)[colnames(df) == "REF_AREA_LABEL"] <- "country"
colnames(df)[colnames(df) == "TIME_PERIOD"] <- "year"
```


```{r}
sum(is.na(df))
colSums(is.na(df)) / nrow(df)

colSums(!is.na(df))
```
Certain columns have a large proportion of missing values which can be worrying when training models. However, these columns still have a large amount of observations despite the proportion of missing values. Since we plan on running a regression on our data, the high proportion of missing data should not have too large of an effect on our model so long as we have a large enough sample size. We can also omit different variables based on missingness and test the accuracy of different regression models. 

#Year
```{r}
hist(df$year)
```
There more data from 2000 to 2020 and less data before 2000 and after 2020.

#Missingness by year

```{r}
missing_year_table <- df %>%
  group_by(year) %>%
  summarize(across(everything(), ~sum(is.na(.)))) %>%
  mutate(total_missing = rowSums(across(-year)))

ggplot(missing_year_table, aes(x = factor(year), y = total_missing)) +
  geom_col() +
  labs(
    title = "Total missing values per year",
    x = "Year",
    y = "Total missing values"
  ) +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))
```
#Missingness by country

```{r}
missing_country <- df %>%
  group_by(country) %>%
  summarize(across(everything(), ~sum(is.na(.)))) %>%
  mutate(total_missing = rowSums(across(-country)))

missing_prop_country <- df %>%
  group_by(country) %>%
  summarize(across(everything(), ~mean(is.na(.))), .groups = "drop") %>%
  mutate(total_missing_prop = rowMeans(across(-country)))

#remove countries with too many missing values
country_keep <- missing_prop_country %>%
  filter(total_missing_prop <= 0.25) %>%
  pull(country)

df <- df %>%
  filter(country %in% country_keep)
```


Our preliminary regression would most likely look something like:

$$
FemaleLabor_i = \beta_0 + \beta_1 EducationExpenditure + \beta_2 BirthRate + \beta_3 FertilityRate + \\ \beta_4 ParentalLeave + \beta_5 TertiaryEnrollment + \beta_6GDP + \beta_7Population + \varepsilon_i
$$
We can explore other options within our model as we explore the relationships between different variables. Introducing exponential variables, interaction terms, time-fixed effects, applying log transformations, or even removing some variables may help improve the accuracy of our model.

We can start making preliminary visualizations for each variable.

#Government Expenditure on Education (% of GDP)
```{r}
summary(df$edu_exp)
hist(df$edu_exp, breaks = 75,
     main = "Distribution of Government Expenditure on Education",
     xlab = "Government Expenditure on Education (% of GDP)")
```
Government expenditure on education displays a right skewed distribution. There are not many outliers, but the outliers that do exist are rather extreme. It may be wise to perform a log transformation to reduce skewness and combat extreme values.


#Birth Rate (per 1000 people)
```{r}
summary(df$birth_rate)
hist(df$birth_rate, breaks = 50,
     main = "Distribution of Birth Rate",
     xlab = "Birth Rate (per 1000 people)")
```
Birth Rates show a right skewed distribution. However, the data is relatively spread out with few to no outliers. Log transformation seems to be unnecessary for birth rates. Something to keep in mind when running birth rates as an independent variable in our regression is reverse causality. We would be exploring the effect of birth rate on female labor rate when in reality it may be female labor rate causing birth rate to behave a certain way. 

#Fertility Rate (births per woman)
```{r}
summary(df$fertility_rate)
hist(df$fertility_rate, breaks = 50,
     main = "Distribution of Fertility Rate",
     xlab = "Fertility Rate (births per woman)")
```
Fertility Rate shows a right skewed distribution. Similar to birth rate there is a relatively even spread of data with few to no outliers. Log transformation seems to be unnecessary. However, we must be careful when including both fertility rate and birth rate in our model it may risk multicollinearity. 

#Length of paid parental leave (calendar days)
```{r}
#mother
summary(df$days_female)
#father
summary(df$days_male)
hist(df$days_female, breaks = 50,
     main = "Distribution of Paid Maternal Leave",
     xlab = "Length of Paid Maternal Leave (calendar days)")
hist(df$days_male, breaks = 50,
     main = "Distribution of Paid Paternal Leave",
     xlab = "Length of Paid Paternal Leave (calendar days)")
```
Data for paid parental leave is extremely right skewed and has many extreme outliers for both genders. Log transformation will most likely be necessary if we want to include this in our model. Paid parental leave is one of the variables with a significant amount of missing values. It should not have too large of an effect on the regression as there are still a significant amount of observations, but it is still something we should be careful about.

#School enrollment, tertiary (% gross)
```{r}
#Female
summary(df$enrolled_female)
#Male
summary(df$enrolled_male)
#Total
summary(df$enrolled_total)
hist(df$enrolled_male, breaks = 50,
     main = "Distribution of Male Tertiary School Enrollment Rate",
     xlab = "Male Tertiary School Enrollment (% gross)")
hist(df$enrolled_female, breaks = 50,
     main = "Distribution of Female Tertiary School Enrollment Rate",
     xlab = "Female Tertiary School Enrollment (% gross)")
hist(df$enrolled_total, breaks = 50,
     main = "Distribution of Tertiary School Enrollment Rate",
     xlab = "Tertiary School Enrollment (% gross)")
```
Tertiary enrollemtn also shows a right skewed distribution. There is a relatively even spread of the data with few outliers. 
#GDP (current US$)
```{r}
summary(df$gdp)
hist(df$gdp, breaks = 50,
     main = "Distribution of GDP",
     xlab = "GDP (current US$)")
```
GDP is heavily right skewed with some extreme outliers. Log transformation will probably be necessary for this variable.
#Population
```{r}
summary(df$population)
hist(df$population, breaks = 50,
     main = "Distribution of Population",
     xlab = "Population")
```
#Female Labor Participation Rate (% of female population age 15+)
```{r}
summary(df$female_labor_rate)
hist(df$female_labor_rate, breaks = 50,
     main = "Distribution of Female Labor Participation Rate",
     xlab = "Female Labor Participation Rate (% of female population age 15+)")
```
Female labor participation rate follow a distribution with little skewness and few outliers.

#Multiple variable visualizations

#Education Expenditure vs Female Labor

```{r}
png("Figure1.png")
plot(
  x = df$edu_exp, y = df$female_labor_rate,
  main = "Education Expenditure vs Female Labor Rate",
  xlab = "Education Expenditure", ylab = "Female Labor Rate",
  col = factor(df$country)
)
```
No particularly clear patterns. Data seems to be rather skewed with a few extreme outliers. Could be a good idea to log education expenditure.

#Birth Rates vs Female Labor

```{r}
plot(
  x = df$birth_rate, y = df$female_labor_rate,
  main = "Birth Rate vs Female Labor Rate",
  xlab = "Birth Rate", ylab = "Female Labor Rate",
  col = factor(df$country)
)
```
No clear patterns between the two variables. Some countries show some patterns but overall there seems to be little to no relationship between the two variables.

#Fertility Rates vs Female Labor

```{r}
png("Figure2.png")
plot(
  x = df$fertility_rate, y = df$female_labor_rate,
  main = "Fertility Rates vs Female Labor Rate",
  xlab = "Fertility Rate", ylab = "Female Labor Rate",
  col = factor(df$country)
)
```
Same as Birth rate.

#Parental Leave vs Female Labor

```{r}
#Maternal
plot(
  x = df$days_female, y = df$female_labor_rate,
  main = "Days of Maternal Leave Given vs Female Labor Rate",
  xlab = "Days of Maternal Leave", ylab = "Female Labor Rate",
  col = factor(df$country)
)

#Paternal
plot(
  x = df$days_male, y = df$female_labor_rate,
  main = "Days of Paternal Leave Given vs Female Labor Rate",
  xlab = "Days of Paternal Leave", ylab = "Female Labor Rate",
  col = factor(df$country)
)

```
Once again no clear pattern

#Correlation Matrix

```{r}
full_cmat <- cor_mat(
  df,
  vars = c(3:ncol(df)),
  method = "pearson",
  alternative = "two.sided",
  conf.level = 0.95
)
print(full_cmat)
```
This is a correlation matrix for all variables. There are a lot of values and we don't have p-values so it is difficult to come to any conclusions from just this. 


```{r}
basic_cmat <- cor_mat(
  df,
  vars = c("year", "edu_exp", "female_labor_rate", "gdp", "birth_rate", "fertility_rate", "days_female", "enrolled_female"),
  method = "pearson",
  alternative = "two.sided",
  conf.level = 0.95
)
print(basic_cmat)


cor_get_pval(basic_cmat)
```
Now we have the reduced correlation matrix with p values, but we can also create a visualization to have a better understanding of the results.

```{r}
png("Figure3.png")
basic_cmat %>%
  cor_reorder() %>%
  pull_lower_triangle() %>%
  cor_plot(label = TRUE)
```
There seems to be very high correlation between fertility rate and birth rate. This makes sense as they are almost the same thing. It is important to consider this when including either variable in a regression model to avoid multicollinearity. Similarly we see a very high correlation between gdp and population. This is also important to keep in mind to avoid multicollinearity. Strong negative correlation between female tertiary enrollment and birth rates.

#Model 0: Female_labor_rate & edu_exp only
```{r}
model0 <- lm(female_labor_rate ~ edu_exp, data = df)
summary(model0)
```
Education expenditure seems to have a negative effect on the female labor rate. It is also significant at the 0.05 level. While the effect is somewhat small, it is different from what is expected. There are a few potential reasons for this. As we saw earlier, edu_exp is very skewed and there are a decent amount of extreme outliers. To combat this we could consider log transforming the variable. Something also to consider is potentially introducing a polynomial term. If edu_exp begins to have a weaker effect as it increases, the polynomial term will help capture this behavior.

#Model 1: First Basic Model
```{r}
model1 <- lm(female_labor_rate ~ edu_exp + year + gdp + population, data = df)
summary(model1)
```
GDP and Population are both insignificant. Coefficients for other variables have become very small. The correlation matrix showed that GDP and Population have very high correlation. This means that there is probably some collinearity present in the model. We will remove Population as GDP tends to be a better parameter when measuring economic factors.

```{r}
model1 <- lm(female_labor_rate ~ edu_exp + year + gdp, data = df)
summary(model1)
```

GDP became more significant but still insignificant at the 0.05 level. edu_exp also became insignificant when removing population. We should try a model with a log transformed edu_exp.

#Model 2: Lin-log model with log transformed edu_exp.

```{r}
#Create log variable
df <- df %>%
  filter(edu_exp > 0)

df <- df %>%
  mutate(log_edu_exp = log(edu_exp))

summary(df$log_edu_exp)
hist(df$log_edu_exp)
```
```{r}
#Run model
model2 <- lm(female_labor_rate ~ log_edu_exp + year + gdp, data = df)
summary(model2)
```

Education expenditure is now much more significant after logging it. GDP remains insignificant. Overall however, the model does not have much explanatory power as the R-squared is only 0.01146. We can try adding more variables to increase the explanatory power of the model.

#Model 3: Including All Variables

```{r}
model3 <- lm(female_labor_rate ~ log_edu_exp + birth_rate + fertility_rate + days_female + enrolled_female + year + gdp, data = df)
summary(model3)
```
Education expenditure becomes insignificant once other variables are added to the model. GDP similarly became largely insignificant. Every other variable is significant at the 0.05 level. However, from looking at the correlation matrix we know there is potentially some multicollinearity so we should run tests and remove variables causing multicollinearity.

```{r}
vif(model3)
```
VIF shows us how much of the variance for a variable is inflated due to correlation with another variable. The lower the value the better. As suspected birth rate and fertility rate are highly correlated and are causing multicollinearity. We can run another model with one of these variables removed. We will drop birth rate because fertility rate gives us information of how many children per woman which will be more helpful.

```{r}
model3 <- lm(female_labor_rate ~ log_edu_exp + fertility_rate + days_female + enrolled_female + year + gdp, data = df)
summary(model3)
vif(model3)
```
Education expenditure and gdp are still insignificant. However, we've eliminated multicollinearity from the model. The R-squared for this model is 0.0785 which much better than model 2, but in terms of explanatory power still relatively low. Something to note is that the coefficient for fertility rate is positive when we should expect a negative relationship between fertility and female labor force participation. This is because intuitively, the more children a woman has, the less time they will have to work a job. There are many ways we can improve the model. We could introduce a quadratic term for fertility, consider region fixed effects or year fixed effect, and potential interaction terms.

#Model 4: Exploring Fertility Rate.

```{r}
#bivariate
fertxlabor1 <- lm(female_labor_rate ~ fertility_rate, data = df)
summary(fertxlabor1)
```
The coefficient for fertility rate is still positive. We would expect the opposite for more developed countries. However, less developed countries will high fertility rates and high female labor participation because most labor would be agricultural in these countries. We can assume that the relationship between fertility rate and female labor force participation across countries is not linear. To capture this behavior we can introduce a quadratic term for fertility rate.

```{r}
#bivariate + quadratic term
fertxlabor2 <- lm(female_labor_rate ~ fertility_rate + I(fertility_rate^2), data = df)
summary(fertxlabor2)
```
As expected, after we introduced the quadratic term the coefficient for fertility rate became negative. The coefficient for the quadratic term however, is positive. This means that at lower fertility rates, there is a negative relationship between fertility and female labor participation and at higher fertility rates, there is a positive relationship between fertility and female labor participation. We can then include the quadratic term in the whole model.

```{r}
model4 <- lm(female_labor_rate ~ log_edu_exp + fertility_rate + I(fertility_rate^2) + days_female + enrolled_female + year, data = df)
summary(model4)
```
After introducing the quadratic term for fertility rates, education expenditure become significant again. The R-squared also increased to 0.1391. I also removed GDP because of its high insignificance.
I would however, like to test out the normal education expenditure instead of the log term.

```{r}
model4 <- lm(female_labor_rate ~ edu_exp + fertility_rate + I(fertility_rate^2) + days_female + enrolled_female + year, data = df)
summary(model4)

```
The normal education expenditure term actually performs better with this model. It's previous lack of significance was likely due to omitted variable bias. With the normal education expenditure the R-squared is slight higher.

Check for multicollinearity just in case.
```{r}
vif(model4)
```
High VIF for fertility rate terms but that is expected. Since they are significant in our model we will leave them as is.

